{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "from sklearn.datasets import load_iris\n", "from sklearn.model_selection import train_test_split"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the DecisionTree class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class DecisionTree:\n", "    def __init__(self, max_depth=5, min_samples_split=2):\n", "        self.max_depth = max_depth\n", "        self.min_samples_split = min_samples_split\n", "    \n", "    def fit(self, X, y):\n", "        # Define the node structure\n", "        class Node:\n", "            def __init__(self, feature_idx=None, threshold=None, left=None, right=None, is_leaf=False, label=None):\n", "                self.feature_idx = feature_idx\n", "                self.threshold = threshold\n", "                self.left = left\n", "                self.right = right\n", "                self.is_leaf = is_leaf\n", "                self.label = label\n", "        \n", "        # Define the entropy calculation function\n", "        def entropy(y):\n", "            _, counts = np.unique(y, return_counts=True)\n", "            p = counts / len(y)\n", "            return -np.sum(p * np.log2(p))\n", "        \n", "        # Define the information gain calculation function\n", "        def info_gain(X, y, feature_idx, threshold):\n", "            left_idx = X[:, feature_idx] < threshold\n", "            left_y = y[left_idx]\n", "            right_y = y[~left_idx]\n", "            p_left = len(left_y) / len(y)\n", "            p_right = 1 - p_left\n", "            ig = entropy(y) - p_left * entropy(left_y) - p_right * entropy(right_y)\n", "            return ig\n", "        \n", "        # Define the recursive splitting function\n", "        def split(X, y, depth):\n", "            # Check if the stopping criterion is met\n", "            if depth >= self.max_depth or len(X) < self.min_samples_split or len(np.unique(y)) == 1:\n", "                label = np.bincount(y).argmax()\n", "                return Node(is_leaf=True, label=label)\n", "            \n", "            # Find the best feature and threshold to split on\n", "            best_feature_idx, best_threshold, best_ig = None, None, 0\n", "            for feature_idx in range(X.shape[1]):\n", "                thresholds = np.unique(X[:, feature_idx])\n", "                for threshold in thresholds:\n", "                    ig = info_gain(X, y, feature_idx, threshold)\n", "                    if ig > best_ig:\n", "                        best_feature_idx, best_threshold, best_ig = feature_idx, threshold, ig\n", "            \n", "            # Split the data and recursively call the function on the left and right nodes\n", "            left_idx = X[:, best_feature_idx] < best_threshold\n", "            right_idx = ~left_idx\n", "            left_node = split(X[left_idx], y[left_idx], depth+1)\n", "            right_node = split(X[right_idx], y[right_idx], depth+1)\n", "            return Node(feature_idx=best_feature_idx, threshold=best_threshold, left=left_node, right=right_node)\n", "        \n", "        # Train the decision tree by recursively splitting the data\n", "        self.root = split(X, y, depth=0)\n", "    \n", "    def predict(self, X):\n", "        # Predict the class labels for the input data\n", "        def traverse(node, x):\n", "            if node.is_leaf:\n", "                return node.label\n", "            if x[node.feature_idx] < node.threshold:\n", "                return traverse(node.left, x)\n", "            else:\n", "                return traverse(node.right, x)\n", "        \n", "        y_pred = np.array([traverse(self.root, x) for x in X])\n", "        return y_pred"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the iris dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iris = load_iris()\n", "X, y = iris.data, iris.target"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Split the data into training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["rain the decision tree"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dt = DecisionTree()\n", "dt.fit(X_train, y_train)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["redict the labels for the test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = dt.predict(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["valuate the performance of the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accuracy = np.sum(y_pred == y_test) / len(y_test)\n", "print(\"Accuracy:\", accuracy)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}